import axios from 'axios';

interface DedalusMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

interface DedalusTool {
  name: string;
  description: string;
  parameters: any;
}

interface DedalusWorkflowRequest {
  prompt: string;
  model?: string;
  tools?: DedalusTool[];
  temperature?: number;
  max_tokens?: number;
}

export interface DedalusWorkflowResponse {
  nodes: any[];
  edges: any[];
  explanation: string;
  reasoning?: string;
  generatedBy?: string;
  model?: string;
}

export class DedalusClient {
  private apiKey: string;
  private baseUrl: string;

  constructor(apiKey?: string, baseUrl?: string) {
    this.apiKey = apiKey || process.env.DEDALUS_API_KEY || '';
    this.baseUrl = baseUrl || process.env.DEDALUS_API_URL || 'https://api.dedaluslabs.ai';
  }

  /**
   * Generate a workflow using Dedalus AI
   */
  async generateWorkflow(request: DedalusWorkflowRequest): Promise<DedalusWorkflowResponse> {
    const systemPrompt = `You are an expert workflow automation designer. Generate workflows as JSON with this structure:
{
  "nodes": [
    {
      "id": "unique-id",
      "type": "workflowNode",
      "position": { "x": number, "y": number },
      "data": {
        "label": "Node Label",
        "icon": "icon-name",
        "color": "#hexcolor",
        "nodeType": "node-type",
        "description": "Brief description"
      }
    }
  ],
  "edges": [
    {
      "id": "edge-id",
      "source": "source-node-id",
      "target": "target-node-id"
    }
  ],
  "explanation": "How this workflow works"
}

Available node types: slack, jira, email, calendar, github, database, webhook, api-call, condition, code, onedrive, excel, sharepoint, teams, asana, trello, notion`;

    try {
      // Use Dedalus API to generate workflow with AI reasoning
      const response = await axios.post(
        `${this.baseUrl}/v1/chat/completions`,
        {
          model: request.model || 'gpt-4-turbo',
          messages: [
            {
              role: 'system',
              content: systemPrompt,
            },
            {
              role: 'user',
              content: request.prompt,
            },
          ],
          temperature: request.temperature || 0.7,
          max_tokens: request.max_tokens || 2000,
          response_format: { type: 'json_object' },
        },
        {
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json',
          },
        }
      );

      const content = response.data.choices[0].message.content;
      let workflowData;

      try {
        workflowData = JSON.parse(content);
      } catch {
        // If response is not pure JSON, try to extract it
        const jsonMatch = content.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          workflowData = JSON.parse(jsonMatch[0]);
        } else {
          throw new Error('Failed to parse workflow JSON from Dedalus response');
        }
      }

      return {
        nodes: workflowData.nodes || [],
        edges: workflowData.edges || [],
        explanation: workflowData.explanation || 'Workflow generated by Dedalus AI',
        reasoning: response.data.choices[0].finish_reason,
      };
    } catch (error: any) {
      console.error('Dedalus API Error:', error.response?.data || error.message);

      // Fallback to a simple workflow if Dedalus fails
      return this.createFallbackWorkflow(request.prompt);
    }
  }

  /**
   * Generate workflow with tool calling and MCP integration
   */
  async generateWorkflowWithTools(
    prompt: string,
    availableIntegrations: string[]
  ): Promise<DedalusWorkflowResponse> {
    const tools: DedalusTool[] = [
      {
        name: 'create_workflow_node',
        description: 'Create a node in the workflow',
        parameters: {
          type: 'object',
          properties: {
            nodeType: { type: 'string', description: 'Type of node (slack, jira, etc.)' },
            label: { type: 'string', description: 'Display label' },
            config: { type: 'object', description: 'Node configuration' },
          },
          required: ['nodeType', 'label'],
        },
      },
      {
        name: 'connect_nodes',
        description: 'Connect two nodes in the workflow',
        parameters: {
          type: 'object',
          properties: {
            source: { type: 'string', description: 'Source node ID' },
            target: { type: 'string', description: 'Target node ID' },
          },
          required: ['source', 'target'],
        },
      },
    ];

    return await this.generateWorkflow({
      prompt: `${prompt}\n\nAvailable integrations: ${availableIntegrations.join(', ')}`,
      tools,
      model: 'gpt-4-turbo',
    });
  }

  /**
   * Chat with Dedalus AI (general purpose)
   */
  async chat(messages: DedalusMessage[], model = 'gpt-4-turbo'): Promise<string> {
    try {
      const response = await axios.post(
        `${this.baseUrl}/v1/chat/completions`,
        {
          model,
          messages,
          temperature: 0.7,
          max_tokens: 1500,
        },
        {
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json',
          },
        }
      );

      return response.data.choices[0].message.content;
    } catch (error: any) {
      console.error('Dedalus Chat Error:', error.response?.data || error.message);
      throw new Error('Failed to get response from Dedalus AI');
    }
  }

  /**
   * Stream workflow generation (for real-time updates)
   */
  async streamWorkflowGeneration(
    prompt: string,
    onChunk: (chunk: string) => void
  ): Promise<DedalusWorkflowResponse> {
    // Note: Streaming implementation would use SSE (Server-Sent Events)
    // For now, we'll use the regular generation and call onChunk once
    const result = await this.generateWorkflow({ prompt });
    onChunk(JSON.stringify(result, null, 2));
    return result;
  }

  /**
   * Test connection to Dedalus API
   */
  async testConnection(): Promise<boolean> {
    try {
      const response = await axios.post(
        `${this.baseUrl}/v1/chat/completions`,
        {
          model: 'gpt-3.5-turbo',
          messages: [{ role: 'user', content: 'Hello' }],
          max_tokens: 5,
        },
        {
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json',
          },
        }
      );

      return response.status === 200;
    } catch {
      return false;
    }
  }

  /**
   * Fallback workflow when API fails
   */
  private createFallbackWorkflow(prompt: string): DedalusWorkflowResponse {
    return {
      nodes: [
        {
          id: 'start-1',
          type: 'workflowNode',
          position: { x: 100, y: 100 },
          data: {
            label: 'Trigger',
            icon: 'webhook',
            color: '#6366F1',
            nodeType: 'webhook',
            description: 'Workflow trigger',
          },
        },
        {
          id: 'action-1',
          type: 'workflowNode',
          position: { x: 350, y: 100 },
          data: {
            label: 'Action',
            icon: 'action',
            color: '#8B5CF6',
            nodeType: 'api-call',
            description: 'Execute action',
          },
        },
      ],
      edges: [
        {
          id: 'edge-1',
          source: 'start-1',
          target: 'action-1',
        },
      ],
      explanation: `I created a basic workflow structure for: "${prompt}". The Dedalus API encountered an issue, so this is a simplified version. Please configure the nodes with your specific requirements.`,
    };
  }
}

// Singleton instance
let dedalusClient: DedalusClient | null = null;

export function getDedalusClient(): DedalusClient {
  if (!dedalusClient) {
    dedalusClient = new DedalusClient();
  }
  return dedalusClient;
}
